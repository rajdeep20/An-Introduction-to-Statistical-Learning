rm(list=ls())
library(ISLR)
library(randomForest)
library(tree)
attach(Carseats)
names(Carseats)
set.seed(2)
sum(is.na(Carseats))

#(a)
sam_size=floor(nrow(Carseats)*0.8)
train=sample(1:nrow(Carseats),sam_size)
sales.test=Carseats$Sales[-train]

#(b)
tree.carseats=tree(Sales~.,data=Carseats,subset=train)
summary(tree.carseats)
yhat=predict(tree.carseats,newdata=Carseats[-train,])
plot(tree.carseats)
text(tree.carseats,pretty=0,cex=0.68)
mean((yhat-sales.test)^2)
#Test MSE is 3.37

#(c)
cv.carseats=cv.tree(tree.carseats,FUN=prune.tree)
cv.carseats
plot(cv.carseats$size,cv.carseats$dev,xlab="terminal nodes",ylab="cv.error",type="b")
prune.carseats=prune.tree(tree.carseats,best=9)
yhat=predict(prune.carseats,newdata=Carseats[-train,])
plot(prune.carseats)
text(prune.carseats,pretty=0,cex=0.68)
mean((yhat-sales.test)^2)
#Prunning in this case increases the test MSE.

#(d)
p=ncol(Carseats)-1
bag.carseats=randomForest(Sales~.,data=Carseats,subset=train,mtry=p,importance=TRUE)
bag.carseats
yhat=predict(bag.carseats,newdata=Carseats[-train,])
mean((yhat-sales.test)^2)
importance(bag.carseats)
#bagging improves the test MSE

#(e)
rf.carseats=randomForest(Sales~.,data=Carseats,subset=train,mtry=sqrt(p),importance=TRUE)
rf.carseats
yhat=predict(rf.carseats,newdata=Carseats[-train,])
mean((yhat-sales.test)^2)
importance(rf.carseats)
#in this case, random forest worsens the test MSE.